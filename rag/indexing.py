import os
from pathlib import Path
import pandas as pd

from rag.doc_loader import detect_columns, create_smart_chunks_from_detected
from rag.embeddings import get_embedding_model
from rag.elasticsearch_indexer import (
    get_elastic_client,
    create_index_if_not_exists,
    index_documents_bulk,
)

# === ğŸ”§ CONFIGURATION ===
# indexing.py est placÃ© dans /rag (racine du code dans le conteneur)
# et docker-compose monte ./data -> /rag/data
BASE_DIR = Path(__file__).resolve().parent           # /rag
DOCS_DIR = Path(os.getenv("DOCS_DIR", str(BASE_DIR / "data" / "documents_xlsx")))
INDEX_NAME = os.getenv("ELASTICSEARCH_INDEX", "rfi_rag")

# ContrÃ´le de la suppression de l'index (par dÃ©faut: False)
REINDEX_DROP = os.getenv("REINDEX_DROP", "false").lower() in {"1", "true", "yes", "y"}


def main() -> None:
    # === ğŸš€ INITIALISATION (faites ici pour Ã©viter les effets Ã  l'import) ===
    print("ğŸ”Œ Connexion Elasticsearchâ€¦")
    es = get_elastic_client()

    print("ğŸ§  Chargement du modÃ¨le d'embeddingsâ€¦")
    embedding_model = get_embedding_model()

    # === ğŸ§¹ GESTION DE L'INDEX ===
    if REINDEX_DROP:
        print(f"ğŸ§¹ Suppression de l'index existant '{INDEX_NAME}' (REINDEX_DROP=true)â€¦")
        if es.indices.exists(index=INDEX_NAME):
            es.indices.delete(index=INDEX_NAME)
            print(f"   Index '{INDEX_NAME}' supprimÃ©.")
        else:
            print(f"   Index '{INDEX_NAME}' inexistant, rien Ã  supprimer.")
    else:
        print("â„¹ï¸ REINDEX_DROP=false â†’ on ne supprime pas l'index existant.")

    create_index_if_not_exists(es, INDEX_NAME)
    print(f"âœ… Index prÃªt : {INDEX_NAME}")

    # === ğŸ“‚ CHARGEMENT & PRÃ‰PARATION DES DOCUMENTS ===
    if not DOCS_DIR.exists():
        raise FileNotFoundError(
            f"Dossier de documents introuvable : {DOCS_DIR}\n"
            "VÃ©rifie le montage de volume dans docker-compose (./data -> /rag/data)."
        )

    all_chunks = []
    xlsx_files = list(DOCS_DIR.glob("*.xlsx"))
    if not xlsx_files:
        print(f"âš ï¸ Aucun fichier .xlsx trouvÃ© dans {DOCS_DIR}")

    for filepath in xlsx_files:
        print(f"\nğŸ“„ Fichier : {filepath.name}")
        all_sheets = pd.read_excel(filepath, sheet_name=None, header=None)

        onglets_exploitables = detect_columns(all_sheets, filepath.name)
        for onglet_data in onglets_exploitables:
            chunks = create_smart_chunks_from_detected(onglet_data, filepath.name)
            all_chunks.extend(chunks)

    print(f"\nâœ… Total de chunks dÃ©tectÃ©s : {len(all_chunks)}")

    if not all_chunks:
        print("â„¹ï¸ Aucun chunk Ã  indexer. Fin.")
        return

    # === ğŸ§  EMBEDDINGS ===
    print("ğŸ”„ CrÃ©ation des embeddingsâ€¦")
    vectors = embedding_model.embed_documents([doc.page_content for doc in all_chunks])

    # === ğŸ“¤ INDEXATION ELASTICSEARCH ===
    print("ğŸ“¦ Indexation dans Elasticsearchâ€¦")
    index_documents_bulk(es, all_chunks, vectors, INDEX_NAME)

    print("ğŸ‰ Pipeline terminÃ© !")


if __name__ == "__main__":
    main()

